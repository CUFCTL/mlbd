{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty Quantification\n",
    "\n",
    "Author: Ben Shealy\n",
    "\n",
    "In this notebook, we will show you how to create regression models that provide __confidence intervals__ around their predictions. Confidence intervals provide a measure of the model's uncertainty around a prediction, which can be useful in many situations. For example, if you wanted to estimate the cost of something based on input features, you might want to make a more conservative estimate when the model provides a larger confidence interval around its prediction.\n",
    "\n",
    "Uncertainty quantification is a huge topic in machine learning, and it is continuously evolving. Here we will describe four techniques that have a proven track record and are easy to use: quantile loss, jackknife, dropout, and conformal intervals. We will use the [Boston house prices dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#boston-dataset) to demonstrate these techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the usual packages, you will need the `forestci` package for jackknife and the `nonconformist` package for conformal intervals. Both of these packages can be installed via `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import forestci\n",
    "import matplotlib.pyplot as plt\n",
    "from nonconformist.cp import IcpRegressor\n",
    "from nonconformist.nc import NcFactory\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load boston housing prices dataset\n",
    "boston = sklearn.datasets.load_boston()\n",
    "\n",
    "# display boston dataset as dataframe\n",
    "pd.DataFrame(\n",
    "    data=np.c_[boston['data'], boston['target']],\n",
    "    columns=list(boston['feature_names']) + ['target']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dataset, target\n",
    "X = boston['data']\n",
    "y = boston['target']\n",
    "\n",
    "# normalize data\n",
    "X = sklearn.preprocessing.scale(X)\n",
    "\n",
    "# create train/test split\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# print shapes of train set and test set\n",
    "print('X_train shape: (%d, %d)' % X_train.shape)\n",
    "print('y_train shape: (%d,)' % y_train.shape)\n",
    "print('X_test shape: (%d, %d)' % X_test.shape)\n",
    "print('y_test shape: (%d,)' % y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile Loss (Gradient Boosting)\n",
    "\n",
    "We can train a gradient boosting model with __quantile loss__, which allows the model to predict a quantile (percentile) of the target distribution. As a comparison, the MAE loss trains the model to predict the median target value (50-th percentile), so the MAE loss is equivalent to the quantile loss with `alpha=0.50`. Therefore, to produce predictions with confidence intervals, we will train three separate models to predict the lower bound, median, and upper bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize models\n",
    "gb_map = {alpha: sklearn.ensemble.GradientBoostingRegressor(loss='quantile', alpha=alpha) for alpha in [0.025, 0.500, 0.975]}\n",
    "\n",
    "# train models\n",
    "for alpha, gb in gb_map.items():\n",
    "    gb.fit(X_train, y_train)\n",
    "\n",
    "# compute predictions with confidence intervals\n",
    "y_preds = {alpha: gb.predict(X_test) for alpha, gb in gb_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute error bars\n",
    "yerr = [\n",
    "    y_preds[0.500] - y_preds[0.025],\n",
    "    y_preds[0.975] - y_preds[0.500]\n",
    "]\n",
    "\n",
    "# plot expected vs predicted values\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.errorbar(\n",
    "    x=y_test,\n",
    "    y=y_preds[0.5],\n",
    "    yerr=yerr,\n",
    "    ecolor='tab:red', c='tab:blue', ls='', marker='o', mec='w')\n",
    "\n",
    "vmax = max(y_test.max(), y_preds[0.5].max())\n",
    "plt.plot([0, vmax], [0, vmax], 'k--', zorder=0)\n",
    "\n",
    "plt.xlabel('Expected')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jackknife (Random Forest)\n",
    "\n",
    "When using a random forest, which is an ensemble of decision trees, the jackknife and the infinitesimal jackknife can be used to obtain an unbiased estimate of the variance of the decision tree predictions. The calculations are somewhat more involved so we will use the `forestci` package to provide the variance estimates. For more information, read the [original paper](https://arxiv.org/abs/1311.4555)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "rf = sklearn.ensemble.RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# compute predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# compute variance estimate\n",
    "V_IJ_U = forestci.random_forest_error(rf, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute error bars\n",
    "yerr = 2.0 * np.sqrt(V_IJ_U)\n",
    "\n",
    "# plot expected vs predicted values\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.errorbar(\n",
    "    x=y_test,\n",
    "    y=y_pred,\n",
    "    yerr=yerr,\n",
    "    ecolor='tab:red', c='tab:blue', ls='', marker='o', mec='w')\n",
    "\n",
    "vmax = max(y_test.max(), y_pred.max())\n",
    "plt.plot([0, vmax], [0, vmax], 'k--', zorder=0)\n",
    "\n",
    "plt.xlabel('Expected')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout (Neural Network)\n",
    "\n",
    "Dropout is a widely used regularization technique for neural networks, in which a portion of randomly sampled weights in the network are disabled during each training iteration. Normally, dropout is disabled during inference, but if we enable dropout then we can construct confidence intervals by taking the distribution of several repeated predictions. For more information, read the [original paper](http://proceedings.mlr.press/v48/gal16.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fn():\n",
    "    hidden_layer_sizes = [128, 128, 128]\n",
    "    l1 = 0\n",
    "    l2 = 1e-5\n",
    "    p_dropout = 0.1\n",
    "    optimizer = 'adam'\n",
    "    loss = 'mean_squared_error'\n",
    "\n",
    "    # create a 3-layer neural network\n",
    "    x_input = keras.Input(shape=X.shape[1])\n",
    "\n",
    "    x = x_input\n",
    "    for units in hidden_layer_sizes:\n",
    "        x = keras.layers.Dense(\n",
    "            units=units,\n",
    "            activation='relu',\n",
    "            kernel_regularizer=keras.regularizers.l1_l2(l1, l2),\n",
    "            bias_regularizer=keras.regularizers.l1_l2(l1, l2)\n",
    "        )(x)\n",
    "\n",
    "        if p_dropout != None:\n",
    "            x = keras.layers.Dropout(p_dropout)(x, training=True)\n",
    "\n",
    "    y_output = keras.layers.Dense(units=1)(x)\n",
    "\n",
    "    mlp = keras.models.Model(x_input, y_output)\n",
    "\n",
    "    # compile the model\n",
    "    mlp.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "    return mlp\n",
    "\n",
    "\n",
    "\n",
    "def inverse_tau(N, lmbda=1e-5, p_dropout=0.1, ls_2=0.005):\n",
    "    return (2 * N * lmbda) / (1 - p_dropout) / ls_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "mlp = keras.wrappers.scikit_learn.KerasRegressor(\n",
    "    build_fn=build_fn,\n",
    "    batch_size=32,\n",
    "    epochs=200,\n",
    "    verbose=False,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "# train model\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# compute several predictions for each sample\n",
    "y_preds = np.array([mlp.predict(X_test) for _ in range(10)])\n",
    "\n",
    "# compute mean and 95% confidence interval\n",
    "y_pred = np.mean(y_preds, axis=0)\n",
    "y_lower = np.percentile(y_preds,  2.5, axis=0)\n",
    "y_upper = np.percentile(y_preds, 97.5, axis=0)\n",
    "\n",
    "# compute tau adjustment\n",
    "tau_inv = inverse_tau(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute error bars\n",
    "yerr = [\n",
    "    (y_pred - y_lower) + 2.0 * tau_inv,\n",
    "    (y_upper - y_pred) + 2.0 * tau_inv\n",
    "]\n",
    "\n",
    "# plot expected vs predicted values\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.errorbar(\n",
    "    x=y_test,\n",
    "    y=y_pred,\n",
    "    yerr=yerr,\n",
    "    ecolor='tab:red', c='tab:blue', ls='', marker='o', mec='w')\n",
    "\n",
    "vmax = max(y_test.max(), y_preds.max())\n",
    "plt.plot([0, vmax], [0, vmax], 'k--', zorder=0)\n",
    "\n",
    "plt.xlabel('Expected')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformal Prediction Intervals\n",
    "\n",
    "This technique can be used with any prediction model. An important difference, however, is that conformal intervals are __prediction intervals__ rather than confidence intervals. Whereas a confidence interval provides a specific value with an interval around it, a prediction interval only provides an interval. While we plot the midpoint of each interval in this example for clarity, in reality we would need more information about the _distribution_ of the interval to obtain the predicted value.\n",
    "\n",
    "To implement conformal intervals, we use the `nonconformist` package to wrap a regression model of our choice into a __nonconformity function__, which in turn is the basis of an __inductive conformal regressor__. This model will provide prediction intervals in lieu of single predictions. For more information, check out the [Github repository](https://github.com/donlnz/nonconformist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/calibration split\n",
    "X_tr, X_cal, y_tr, y_cal = sklearn.model_selection.train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "# create underlying model\n",
    "model = sklearn.ensemble.RandomForestRegressor()\n",
    "\n",
    "# create nonconformity function\n",
    "nc = NcFactory.create_nc(model)\n",
    "\n",
    "# create inductive conformal regressor\n",
    "icp = IcpRegressor(nc)\n",
    "\n",
    "# train model\n",
    "icp.fit(X_tr, y_tr)\n",
    "\n",
    "# calibrate model\n",
    "icp.calibrate(X_cal, y_cal)\n",
    "\n",
    "# compute predictions on test data (with 95% confidence)\n",
    "y_pred = icp.predict(X_test, significance=0.05)\n",
    "\n",
    "# separate predictions into lower and upper bounds\n",
    "y_lower = y_pred[:, 0]\n",
    "y_upper = y_pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot expected vs predicted values\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.errorbar(\n",
    "    x=y_test,\n",
    "    y=(y_lower + y_upper) / 2,\n",
    "    yerr=(y_lower - y_upper) / 2,\n",
    "    ecolor='tab:red', c='tab:blue', ls='', marker='o', mec='w')\n",
    "\n",
    "vmax = max(y_test.max(), y_upper.max())\n",
    "plt.plot([0, vmax], [0, vmax], 'k--', zorder=0)\n",
    "\n",
    "plt.xlabel('Expected')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (mlbd)",
   "language": "python",
   "name": "mlbd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
